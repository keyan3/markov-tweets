{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "727d86148491e8268741fb9ad1182f32",
     "grade": false,
     "grade_id": "tweepy",
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# EECS 126 MCMC Project - Generating Trump Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "727d86148491e8268741fb9ad1182f32",
     "grade": false,
     "grade_id": "tweepy",
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import tweepy\n",
    "\n",
    "# Ensure that we can see full tweets\n",
    "pd.set_option('max_colwidth', 280)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Building Tweet Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing API Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2eb5fb9a1af6832165a365b0aad21ab",
     "grade": false,
     "grade_id": "keys",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Loading previously generated API authentication keys\n",
    "import json\n",
    "key_file = 'keys.json'\n",
    "\n",
    "with open(key_file) as f:\n",
    "    keys = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66806331fe1cb852ab300e98459cb2d4",
     "grade": false,
     "grade_id": "twitter-auth",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your username is: gorblamski\n"
     ]
    }
   ],
   "source": [
    "from tweepy import TweepError\n",
    "import logging\n",
    "\n",
    "try:\n",
    "    auth = tweepy.OAuthHandler(keys[\"consumer_key\"], keys[\"consumer_secret\"])\n",
    "    auth.set_access_token(keys[\"access_token\"], keys[\"access_token_secret\"])\n",
    "    api = tweepy.API(auth)\n",
    "    print(\"Your username is:\", api.auth.get_username())\n",
    "except TweepError as e:\n",
    "    logging.warning(\"Tweepy error\")\n",
    "    logging.warning(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "727d86148491e8268741fb9ad1182f32",
     "grade": false,
     "grade_id": "tweepy",
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ds_tweets_save_path = \"BerkeleyData_recent_tweets.json\"\n",
    "\n",
    "# Guarding against attempts to download the data multiple times:\n",
    "if not Path(ds_tweets_save_path).is_file():\n",
    "    example_tweets = [t._json for t in tweepy.Cursor(api.user_timeline, id=\"BerkeleyData\", \n",
    "                                             tweet_mode='extended').items()]\n",
    "    \n",
    "    # Saving the tweets to a json file on disk for future analysis\n",
    "    with open(ds_tweets_save_path, \"w\") as f:        \n",
    "        json.dump(example_tweets, f)\n",
    "\n",
    "# Re-loading the json file:\n",
    "with open(ds_tweets_save_path, \"r\") as f:\n",
    "    example_tweets = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43ce65ddda5bb1543856611dd2c536f9",
     "grade": false,
     "grade_id": "q2a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Functions for obtaining tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd6de9d61c340450539455afd0f8fdf3",
     "grade": false,
     "grade_id": "load-keys",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Loads Twitter authentication keys\n",
    "def load_keys(path):\n",
    "    key_file = 'keys.json'\n",
    "    with open(key_file) as f:\n",
    "        keys = json.load(f)\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76ff200bf064ab3f5c457bc4725d8cd8",
     "grade": false,
     "grade_id": "download-recent-tweets",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Downloads tweets by one Twitter user.\n",
    "def download_recent_tweets_by_user(user_account_name, keys):\n",
    "    import tweepy\n",
    "    auth = tweepy.OAuthHandler(keys[\"consumer_key\"], keys[\"consumer_secret\"])\n",
    "    auth.set_access_token(keys[\"access_token\"], keys[\"access_token_secret\"])\n",
    "    api = tweepy.API(auth)\n",
    "    return [t._json for t in tweepy.Cursor(api.user_timeline, id=user_account_name, \n",
    "                                             tweet_mode='extended').items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75d788899e9212031d95685b7ebb4505",
     "grade": false,
     "grade_id": "save-tweets",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Saves a list of tweets to a file\n",
    "def save_tweets(tweets, path):\n",
    "    with open(path, \"w\") as f:        \n",
    "        json.dump(tweets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31f5a74addf3b0211c65b0220160568c",
     "grade": false,
     "grade_id": "load-tweets",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Loads tweets that have previously been saved.\n",
    "def load_tweets(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c2633d5128de6e4aadf225aa291118d",
     "grade": false,
     "grade_id": "get-tweets-with-cache",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Get recent tweets from one user, loading from cache if possible\n",
    "def get_tweets_with_cache(user_account_name, keys_path):\n",
    "    keys = load_keys(keys_path)\n",
    "    if not Path(user_account_name + \"tweets.json\").is_file():\n",
    "        tweet_list = download_recent_tweets_by_user(user_account_name, keys)\n",
    "        save_tweets(tweet_list, user_account_name + \"tweets.json\")\n",
    "    else:\n",
    "        tweet_list = load_tweets(user_account_name + \"tweets.json\")\n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping trump tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ac3bb2120526571535abbe412929bfd",
     "grade": false,
     "grade_id": "trump-tweets",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets downloaded: 3191\n"
     ]
    }
   ],
   "source": [
    "trump_tweets = get_tweets_with_cache(\"realdonaldtrump\", key_file)\n",
    "print(\"Number of tweets downloaded:\", len(trump_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging scraped tweets with existing Trump tweet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ac0f2bbd264f78c5709e04bfaee390d",
     "grade": false,
     "grade_id": "download-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version already downloaded: Sat Oct 27 02:13:31 2018\n",
      "MD5 hash of file: b6e33874de91d1a40207cdf9f9b51a09\n",
      "Located at data/old_trump_tweets.json.zip\n"
     ]
    }
   ],
   "source": [
    "from utils import fetch_and_cache\n",
    "data_url = 'http://www.ds100.org/fa18/assets/datasets/old_trump_tweets.json.zip'\n",
    "file_name = 'old_trump_tweets.json.zip'\n",
    "\n",
    "dest_path = fetch_and_cache(data_url=data_url, file=file_name)\n",
    "print(f'Located at {dest_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f84519e987875b6b57d9cc5bae460cf",
     "grade": false,
     "grade_id": "loading-old-tweets",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "my_zip = zipfile.ZipFile(dest_path, 'r')\n",
    "with my_zip.open(\"old_trump_tweets.json\", \"r\") as f:\n",
    "    old_trump_tweets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c88eaf1ba38e6c52151ad6a2922216c0",
     "grade": false,
     "grade_id": "listing-keys",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['created_at', 'id', 'id_str', 'text', 'truncated', 'entities', 'extended_entities', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive', 'lang'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_trump_tweets[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfff2cf8e110d51cb3dbb7f5086b9be4",
     "grade": false,
     "grade_id": "q3a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "all_tweets = []\n",
    "new_trump_tweet_ids = set([t['id'] for t in trump_tweets])\n",
    "for old_tweet in old_trump_tweets:\n",
    "    if old_tweet['id'] not in new_trump_tweet_ids:\n",
    "        all_tweets.append(old_tweet)\n",
    "\n",
    "all_tweets += trump_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a21da10aa86da615b340c8edb2973c3",
     "grade": true,
     "grade_id": "q3a-test",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(all_tweets) > len(trump_tweets)\n",
    "assert len(all_tweets) > len(old_trump_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating pandas dataframe of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt = [tweet['text'] if 'text' in tweet.keys() else tweet['full_text'] for tweet in all_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbbe93f4346b0c4ce93681c2c7d06078",
     "grade": false,
     "grade_id": "q3b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "trump = pd.DataFrame(all_tweets)[['created_at', 'id', 'source', 'retweet_count']].set_index('id', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump['text'] = pd.Series(data=txt, index=trump.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>690171032150237184</th>\n",
       "      <td>Thu Jan 21 13:56:11 +0000 2016</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;</td>\n",
       "      <td>1059</td>\n",
       "      <td>\"@bigop1: @realDonaldTrump  @SarahPalinUSA https://t.co/3kYQGqeVyD\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690171403388104704</th>\n",
       "      <td>Thu Jan 21 13:57:39 +0000 2016</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;</td>\n",
       "      <td>1339</td>\n",
       "      <td>\"@AmericanAsPie:  @glennbeck @SarahPalinUSA Remember when Glenn gave out gifts to ILLEGAL ALIENS at crossing the border? Me too!\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690173226341691392</th>\n",
       "      <td>Thu Jan 21 14:04:54 +0000 2016</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;</td>\n",
       "      <td>2006</td>\n",
       "      <td>So sad that @CNN and many others refused to show the massive crowd at the arena yesterday in Oklahoma. Dishonest reporting!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690176882055114758</th>\n",
       "      <td>Thu Jan 21 14:19:26 +0000 2016</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;</td>\n",
       "      <td>2266</td>\n",
       "      <td>Sad sack @JebBush has just done another ad on me, with special interest money, saying I won't beat Hillary - I WILL. But he can't beat me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690180284189310976</th>\n",
       "      <td>Thu Jan 21 14:32:57 +0000 2016</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;</td>\n",
       "      <td>2886</td>\n",
       "      <td>Low energy candidate @JebBush has wasted $80 million on his failed presidential campaign. Millions spent on me. He should go home and relax!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        created_at  \\\n",
       "id                                                   \n",
       "690171032150237184  Thu Jan 21 13:56:11 +0000 2016   \n",
       "690171403388104704  Thu Jan 21 13:57:39 +0000 2016   \n",
       "690173226341691392  Thu Jan 21 14:04:54 +0000 2016   \n",
       "690176882055114758  Thu Jan 21 14:19:26 +0000 2016   \n",
       "690180284189310976  Thu Jan 21 14:32:57 +0000 2016   \n",
       "\n",
       "                                                                                                  source  \\\n",
       "id                                                                                                         \n",
       "690171032150237184  <a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>   \n",
       "690171403388104704  <a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>   \n",
       "690173226341691392  <a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>   \n",
       "690176882055114758  <a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>   \n",
       "690180284189310976  <a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>   \n",
       "\n",
       "                    retweet_count  \\\n",
       "id                                  \n",
       "690171032150237184           1059   \n",
       "690171403388104704           1339   \n",
       "690173226341691392           2006   \n",
       "690176882055114758           2266   \n",
       "690180284189310976           2886   \n",
       "\n",
       "                                                                                                                                                            text  \n",
       "id                                                                                                                                                                \n",
       "690171032150237184                                                                           \"@bigop1: @realDonaldTrump  @SarahPalinUSA https://t.co/3kYQGqeVyD\"  \n",
       "690171403388104704             \"@AmericanAsPie:  @glennbeck @SarahPalinUSA Remember when Glenn gave out gifts to ILLEGAL ALIENS at crossing the border? Me too!\"  \n",
       "690173226341691392                   So sad that @CNN and many others refused to show the massive crowd at the arena yesterday in Oklahoma. Dishonest reporting!  \n",
       "690176882055114758    Sad sack @JebBush has just done another ad on me, with special interest money, saying I won't beat Hillary - I WILL. But he can't beat me.  \n",
       "690180284189310976  Low energy candidate @JebBush has wasted $80 million on his failed presidential campaign. Millions spent on me. He should go home and relax!  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Additional data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump.sort_index(inplace=True)\n",
    "trump['time'] = pd.to_datetime(trump['created_at'])\n",
    "trump = trump.drop('created_at', axis=1)\n",
    "source_pat = \"(>.*<)\"\n",
    "trump['source'] = trump['source'].str.extract(source_pat)\n",
    "trump['source'] = trump['source'].str.replace(\">\", \"\")\n",
    "trump['source'] = trump['source'].str.replace(\"<\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>690171032150237184</th>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>1059</td>\n",
       "      <td>\"@bigop1: @realDonaldTrump  @SarahPalinUSA https://t.co/3kYQGqeVyD\"</td>\n",
       "      <td>2016-01-21 13:56:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690171403388104704</th>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>1339</td>\n",
       "      <td>\"@AmericanAsPie:  @glennbeck @SarahPalinUSA Remember when Glenn gave out gifts to ILLEGAL ALIENS at crossing the border? Me too!\"</td>\n",
       "      <td>2016-01-21 13:57:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690173226341691392</th>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>2006</td>\n",
       "      <td>So sad that @CNN and many others refused to show the massive crowd at the arena yesterday in Oklahoma. Dishonest reporting!</td>\n",
       "      <td>2016-01-21 14:04:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690176882055114758</th>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>2266</td>\n",
       "      <td>Sad sack @JebBush has just done another ad on me, with special interest money, saying I won't beat Hillary - I WILL. But he can't beat me.</td>\n",
       "      <td>2016-01-21 14:19:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690180284189310976</th>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>2886</td>\n",
       "      <td>Low energy candidate @JebBush has wasted $80 million on his failed presidential campaign. Millions spent on me. He should go home and relax!</td>\n",
       "      <td>2016-01-21 14:32:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 source  retweet_count  \\\n",
       "id                                                       \n",
       "690171032150237184  Twitter for Android           1059   \n",
       "690171403388104704  Twitter for Android           1339   \n",
       "690173226341691392  Twitter for Android           2006   \n",
       "690176882055114758  Twitter for Android           2266   \n",
       "690180284189310976  Twitter for Android           2886   \n",
       "\n",
       "                                                                                                                                                            text  \\\n",
       "id                                                                                                                                                                 \n",
       "690171032150237184                                                                           \"@bigop1: @realDonaldTrump  @SarahPalinUSA https://t.co/3kYQGqeVyD\"   \n",
       "690171403388104704             \"@AmericanAsPie:  @glennbeck @SarahPalinUSA Remember when Glenn gave out gifts to ILLEGAL ALIENS at crossing the border? Me too!\"   \n",
       "690173226341691392                   So sad that @CNN and many others refused to show the massive crowd at the arena yesterday in Oklahoma. Dishonest reporting!   \n",
       "690176882055114758    Sad sack @JebBush has just done another ad on me, with special interest money, saying I won't beat Hillary - I WILL. But he can't beat me.   \n",
       "690180284189310976  Low energy candidate @JebBush has wasted $80 million on his failed presidential campaign. Millions spent on me. He should go home and relax!   \n",
       "\n",
       "                                  time  \n",
       "id                                      \n",
       "690171032150237184 2016-01-21 13:56:11  \n",
       "690171403388104704 2016-01-21 13:57:39  \n",
       "690173226341691392 2016-01-21 14:04:54  \n",
       "690176882055114758 2016-01-21 14:19:26  \n",
       "690180284189310976 2016-01-21 14:32:57  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing links, newlines, quotes, 'amp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump['text'] = trump['text'].str.replace(r'(https){1}.*', '')\n",
    "trump['text'] = trump['text'].str.replace(r'(\\n){1}', '')\n",
    "trump['text'] = trump['text'].str.replace(r'\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump['text'] = trump['text'].str.replace(r'(&amp){1}', '&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump['text'] = trump['text'].str.replace(r'(&;){1}', '&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tcopy = trump['text'].str.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Constructing Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in tcopy.index:\n",
    "    tcopy.loc[i] = [x for x in tcopy.loc[i] if x != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "unique_words = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in tcopy.index[:1000]:\n",
    "    for j in tcopy.loc[i]:\n",
    "        unique_words[j] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_tprobs_for_word(w):\n",
    "    trans_dict = defaultdict(int)\n",
    "    total_trans = 0\n",
    "    for i in tcopy.index[:1000]:\n",
    "        curr_tweet = tcopy.loc[i]\n",
    "        for i in range(len(curr_tweet)):\n",
    "            curr_word = curr_tweet[i]\n",
    "            if curr_word == w and i != (len(curr_tweet) - 1):\n",
    "                next_word = curr_tweet[i + 1]\n",
    "                trans_dict[next_word] += 1\n",
    "                total_trans += 1\n",
    "    for k in trans_dict:\n",
    "        trans_dict[k] /= total_trans\n",
    "    return trans_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4819"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markov_dict = defaultdict(int)\n",
    "for u in unique_words:\n",
    "    markov_dict[u] = generate_tprobs_for_word(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4819"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(markov_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "for key, value in markov_dict['at'].items():\n",
    "    lst.append((key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('crossing', 0.013333333333333334),\n",
       " ('the', 0.22666666666666666),\n",
       " ('an', 0.013333333333333334),\n",
       " ('9pm', 0.02666666666666667),\n",
       " ('various', 0.02666666666666667),\n",
       " ('around', 0.02666666666666667),\n",
       " ('7:30', 0.013333333333333334),\n",
       " ('41%', 0.013333333333333334),\n",
       " ('my', 0.02666666666666667),\n",
       " ('8:00', 0.013333333333333334),\n",
       " ('Drake', 0.013333333333333334),\n",
       " ('7:00', 0.02666666666666667),\n",
       " ('their', 0.013333333333333334),\n",
       " ('minimum.', 0.013333333333333334),\n",
       " ('8pm', 0.013333333333333334),\n",
       " ('stake.', 0.013333333333333334),\n",
       " ('Clemson', 0.013333333333333334),\n",
       " ('me.', 0.013333333333333334),\n",
       " ('9am.', 0.013333333333333334),\n",
       " ('7:02', 0.013333333333333334),\n",
       " ('this', 0.013333333333333334),\n",
       " ('Jeb', 0.013333333333333334),\n",
       " ('bottom', 0.013333333333333334),\n",
       " ('8:40.', 0.013333333333333334),\n",
       " ('least', 0.013333333333333334),\n",
       " ('all!', 0.013333333333333334),\n",
       " ('it', 0.013333333333333334),\n",
       " ('meetings', 0.013333333333333334),\n",
       " ('5pm.', 0.013333333333333334),\n",
       " ('1%,', 0.013333333333333334),\n",
       " ('10pm', 0.02666666666666667),\n",
       " ('10:10pm.', 0.013333333333333334),\n",
       " ('10pmE.', 0.013333333333333334),\n",
       " ('10:00', 0.013333333333333334),\n",
       " ('8:00.', 0.013333333333333334),\n",
       " ('12:00', 0.013333333333333334),\n",
       " ('Fort', 0.013333333333333334),\n",
       " ('11:30', 0.013333333333333334),\n",
       " ('8:30', 0.02666666666666667),\n",
       " ('8pmE', 0.013333333333333334),\n",
       " ('7pmE', 0.013333333333333334),\n",
       " ('stake', 0.013333333333333334),\n",
       " ('#KansasCaucus.', 0.013333333333333334),\n",
       " ('Trump', 0.02666666666666667),\n",
       " ('3:00', 0.013333333333333334),\n",
       " ('43%', 0.013333333333333334),\n",
       " ('Mar-a-Lago', 0.013333333333333334),\n",
       " ('7:15', 0.013333333333333334),\n",
       " ('7:40.', 0.013333333333333334),\n",
       " ('8', 0.013333333333333334),\n",
       " ('math.', 0.013333333333333334)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Generating Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for random walk on Tweet Markov chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def gen_tweet_given_start(start, length):\n",
    "    assert start in unique_words\n",
    "    ct = 0\n",
    "    prob = 1\n",
    "    tweet = start + ' '\n",
    "    state = [(key, value) for key, value in markov_dict[start].items()]\n",
    "    while ct != length:\n",
    "        br = False\n",
    "        success = 0\n",
    "        fail_count = 0\n",
    "        while not success:\n",
    "            s_ind = 0\n",
    "            ran = random.uniform(0, 1)\n",
    "            ran -= state[s_ind][1]\n",
    "            while ran > 0:\n",
    "                s_ind += 1\n",
    "                ran -= state[s_ind][1]\n",
    "            next_word = state[s_ind][0]\n",
    "            if next_word in markov_dict and len(markov_dict[next_word]) >= 1:\n",
    "                success = 1\n",
    "                prob *= state[s_ind][1]\n",
    "                tweet += (next_word + ' ')\n",
    "                ct += 1\n",
    "                state = [(key, value) for key, value in markov_dict[next_word].items()]\n",
    "            fail_count += 1\n",
    "            if fail_count > 100:\n",
    "                br = True\n",
    "                break\n",
    "        if br:\n",
    "            break\n",
    "    return tweet, prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best = ['Ted Cruz lies and he runs ', \n",
    "        'Ted Cruz campaign is very sleazy ', \n",
    "        'Obama is working with Trump. Thank you people ',\n",
    "        'Jeb Bush has ties to Trump and Cruz ',\n",
    "        \"Bush just on @FoxNews - I wasn't enough \",\n",
    "        \"Marco 'Amnesty' Rubio is thinking of little Mort \",\n",
    "        'Marco Rubio was as if he is weak ',\n",
    "        'Marco Rubio is jealous of Cruz & strong ',\n",
    "        'Trump has a dinner in bed ',\n",
    "        'Democrats numbers have done the dying ',\n",
    "        'I did a WALL and ObamaCare, ',\n",
    "        'I could be just another politician. ',\n",
    "        'Trump won all the evangelical vote ',\n",
    "        'ISIS is a person in Salem, ',\n",
    "        'ISIS is better than a rock! ',\n",
    "        \"I'm going to church I WILL. \",\n",
    "        'many believe @realDonaldTrump Wow! Thank you, ',\n",
    "        'so easy to be president - ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests with various start words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ted Cruz to me. I must ', 1.8470064073831216e-08),\n",
       " ('Ted may be happy to watching ', 2.9675379832991706e-08),\n",
       " ('Ted Cruz & not on my ', 8.269718196200094e-08),\n",
       " ('Ted Cruz lies and he runs ', 8.997584818509143e-08),\n",
       " ('Ted Cruz, and demanding a man ', 9.185935084099072e-08),\n",
       " ('Ted Cruz to donate and deceptive ', 9.383984166543278e-08),\n",
       " (\"Ted can't beat him that @CNN \", 1.3882317282675216e-07),\n",
       " ('Ted Cruz, Rubio and special guy! ', 2.2755834747734885e-07),\n",
       " ('Ted Cruz be great people we ', 2.4715402469229096e-07),\n",
       " ('Ted Cruz campaign is very sleazy ', 3.6808936495531105e-07)]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for _ in range(100):\n",
    "    tweets.append(gen_tweet_given_start(\"Ted\", 5))\n",
    "curr = sorted(tweets, key = lambda x: x[1])[0:10]\n",
    "curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Obama is such a big & the evening. ', 3.683733992282364e-11),\n",
       " ('Obama would beat you in lie to do ', 9.086065127868122e-11),\n",
       " ('Obama is underway @realDonaldTrump Trump will not careful, ',\n",
       "  2.9046102973826e-10),\n",
       " ('Obama would not Trump will be a dinner ', 3.146953472772636e-10),\n",
       " ('Obama would the people I will do on ', 1.153588398491367e-09),\n",
       " ('Obama is repulsive that I stated on 3/8/2016. ', 1.2224064242014723e-09),\n",
       " ('Obama is working with Trump. Thank you people ', 2.7038665951790717e-09),\n",
       " ('Obama is a stacked RNC and the chaos ', 3.2710778028747256e-09),\n",
       " ('Obama so many more for the primary vote ', 3.5581226907221935e-09),\n",
       " ('Obama so big, Cruz, and and get out ', 5.184663615706427e-09)]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for _ in range(100):\n",
    "    tweets.append(gen_tweet_given_start(\"Obama\", 7))\n",
    "curr = sorted(tweets, key = lambda x: x[1])[0:10]\n",
    "curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Jeb spent so out the media wasn't enough \", 1.7900228169339606e-10),\n",
       " ('Jeb and a weak on this morning. Glad ', 4.3783486184892456e-10),\n",
       " ('Jeb and other Republican Party see the highly ', 6.186185460489041e-10),\n",
       " ('Jeb Bush has done the winner of himself. ', 8.813934219230215e-10),\n",
       " ('Jeb Bush is all the new voters that ', 1.6448768147495032e-09),\n",
       " ('Jeb and vote total #Mediafraud. When you Kansas! ', 4.3396285286658715e-09),\n",
       " ('Jeb Bush has ties to Trump and Cruz ', 6.616259174406837e-09),\n",
       " ('Jeb Bush in NH GOP candidates are way ', 7.301429590708142e-09),\n",
       " ('Jeb --- Just in, big & many voters ', 7.737986574655196e-09),\n",
       " ('Jeb Bush was told to my forum with ', 7.902124613268439e-09)]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for _ in range(100):\n",
    "    tweets.append(gen_tweet_given_start(\"Jeb\", 7))\n",
    "curr = sorted(tweets, key = lambda x: x[1])[0:10]\n",
    "curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bush and a major speeches and is by ', 7.58411795438427e-11),\n",
       " ('Bush is afraid of Iowa love to thank ', 2.2874980198094679e-10),\n",
       " (\"Bush just on @FoxNews - I wasn't enough \", 2.9305667200989573e-10),\n",
       " ('Bush is at Trump winning debate tonight because ', 4.775252445212783e-10),\n",
       " ('Bush in America Needs: The people are spending ', 8.272555693905776e-10),\n",
       " ('Bush and Jeb spent very successful event is ', 1.0279785159398183e-09),\n",
       " ('Bush was great experience in his votes than ', 1.0519599368548003e-09),\n",
       " ('Bush is because of @StJude in Salt Lake ', 1.2214780985788866e-09),\n",
       " ('Bush spent against Trump has cancelled the special ',\n",
       "  1.2332162961739611e-09),\n",
       " ('Bush is going to be president in Manchester, ', 1.2982888379067002e-09)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for _ in range(100):\n",
    "    tweets.append(gen_tweet_given_start(\"Bush\", 7))\n",
    "curr = sorted(tweets, key = lambda x: x[1])[0:10]\n",
    "curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Marco Rubio is jealous of Cruz & strong ', 1.9196447098869053e-10),\n",
       " ('Marco Rubio & the century the warm embrace ', 1.5202635131310505e-09),\n",
       " ('Marco Rubio was as if he is weak ', 1.7433880865613842e-09),\n",
       " ('Marco Rubio was so much to the advertisers ', 2.310660416910899e-09),\n",
       " ('Marco made so happy to help you for ', 2.8390806261989783e-09),\n",
       " ('Marco Rubio gave up a disaster for Rubio, ', 4.14364382714961e-09),\n",
       " ('Marco Rubio to the people of time we ', 4.869131977967355e-09),\n",
       " ('Marco Rubio 15.0 Cruz talks about to contribute ', 6.707848775107442e-09),\n",
       " (\"Marco 'Amnesty' Rubio is thinking of little Mort \", 6.9312072825363165e-09),\n",
       " ('Marco Rubio, who will change in Canada Cruz ', 7.33268571053138e-09)]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for _ in range(100):\n",
    "    tweets.append(gen_tweet_given_start(\"Marco\", 7))\n",
    "curr = sorted(tweets, key = lambda x: x[1])[0:10]\n",
    "curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Trump line and to Trump like ', 2.0360312376056597e-09),\n",
       " ('Trump is to compete in American ', 3.797385567304884e-09),\n",
       " ('Trump won that while the remaining ', 1.7602994128477303e-08),\n",
       " ('Trump had to get to do ', 2.520391648699075e-08),\n",
       " ('Trump is looking good for himselfâ€”a ', 3.2589910908494975e-08),\n",
       " ('Trump campaign & invest in Madison, ', 3.8283549405686184e-08),\n",
       " ('Trump has a dinner in bed ', 5.056043716576391e-08),\n",
       " ('Trump about @FoxNews Listening to Tampa ', 6.311696836577547e-08),\n",
       " ('Trump about Hillary would have killed ', 6.777381978670222e-08),\n",
       " ('Trump is Clinton and running in ', 7.709441290181607e-08)]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for _ in range(100):\n",
    "    tweets.append(gen_tweet_given_start(\"Trump\", 5))\n",
    "curr = sorted(tweets, key = lambda x: x[1])[0:10]\n",
    "curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Democrats vote. The great & replace. ', 3.538870958609365e-07),\n",
       " ('Democrats would be just got ZERO, ', 5.269167122324167e-07),\n",
       " ('Democrats would never run, a small ', 7.273192757063725e-07),\n",
       " ('Democrats numbers have done the dying ', 1.1156854213385992e-06),\n",
       " ('Democrats working so out from his ', 1.17039417705489e-06),\n",
       " ('Democrats would have the stage. Not ', 1.5213892109162715e-06),\n",
       " ('Democrats working with very good chance ', 1.6546648310918137e-06),\n",
       " ('Democrats numbers in Dayton & dry. ', 2.067311667907054e-06),\n",
       " ('Democrats working hard in the sports ', 2.119245358767894e-06),\n",
       " ('Democrats numbers are for Trump. DT ', 2.7056277056277056e-06)]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for _ in range(100):\n",
    "    tweets.append(gen_tweet_given_start(\"Democrats\", 5))\n",
    "curr = sorted(tweets, key = lambda x: x[1])[0:10]\n",
    "curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I did great debate Cruz - ', 2.286321532713374e-09),\n",
       " ('I hope you win in Tampa! ', 7.791038124665959e-09),\n",
       " ('I do w/ a very good ', 1.1228788817922944e-08),\n",
       " ('I did a WALL and ObamaCare, ', 1.7205402221010963e-08),\n",
       " ('I must talk and a WALL ', 4.014593851569224e-08),\n",
       " ('I was able to him the ', 4.6780811847574754e-08),\n",
       " ('I would end this great President, ', 5.5581493585895636e-08),\n",
       " ('I can join the race, someone ', 8.772911005397534e-08),\n",
       " ('I would say in Iowa, he ', 8.98382193346222e-08),\n",
       " ('I did he was an even ', 9.301633366819214e-08)]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for _ in range(100):\n",
    "    tweets.append(gen_tweet_given_start(\"I\", 5))\n",
    "curr = sorted(tweets, key = lambda x: x[1])[0:10]\n",
    "curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Trump up to speak the warm ', 3.0274616199608057e-09),\n",
       " ('Trump held in Canada to unite ', 2.0433550909783423e-08),\n",
       " ('Trump winning the leaders in defending ', 2.3076227239917077e-08),\n",
       " ('Trump was amazing day for lightweight ', 2.7508197442837967e-08),\n",
       " ('Trump way that is a leader ', 3.501147928373572e-08),\n",
       " ('Trump is not as bad word. ', 3.623897429207164e-08),\n",
       " ('Trump has his family in Ohio. ', 3.6879377697380734e-08),\n",
       " ('Trump shows that there - TRUMP ', 5.107147964290821e-08),\n",
       " ('Trump for Kasich is incompetent Mitt ', 7.010938817289676e-08),\n",
       " ('Trump won all the evangelical vote ', 8.233400435546883e-08)]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for _ in range(100):\n",
    "    tweets.append(gen_tweet_given_start(\"Trump\", 5))\n",
    "curr = sorted(tweets, key = lambda x: x[1])[0:10]\n",
    "curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ISIS is that Jeb is way ', 1.042342524454919e-07),\n",
       " ('ISIS is amazing. We the founder ', 1.3101139222662245e-07),\n",
       " ('ISIS is he spent a choker, ', 2.099041157999026e-07),\n",
       " ('ISIS is about Trump National Zogby ', 2.142231305282957e-07),\n",
       " ('ISIS is lying is not caring ', 3.968648733313155e-07),\n",
       " ('ISIS is I put on the ', 4.312649864582795e-07),\n",
       " ('ISIS is losing jobs in many ', 5.684453701261493e-07),\n",
       " ('ISIS is a person in Salem, ', 5.776138438378616e-07),\n",
       " ('ISIS is so the only when ', 5.927174909329041e-07),\n",
       " ('ISIS is by Cruz apart for ', 6.79689517828256e-07)]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for _ in range(100):\n",
    "    tweets.append(gen_tweet_given_start(\"ISIS\", 5))\n",
    "curr = sorted(tweets, key = lambda x: x[1])[0:10]\n",
    "curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"I'm not watch her a morning \", 1.0887107661301211e-07),\n",
       " (\"I'm a dog-over and didn't meet \", 1.659092357026057e-07),\n",
       " (\"I'm going very incompetent and never \", 3.789716226048993e-07),\n",
       " (\"I'm fed up and that when \", 4.521482467499584e-07),\n",
       " (\"I'm like a @FoxNews only wish \", 4.850836769342712e-07),\n",
       " (\"I'm going to church I WILL. \", 5.951028445915971e-07),\n",
       " (\"I'm not controlled by his prize, \", 6.105319198298325e-07),\n",
       " (\"I'm going to support & his \", 6.925765863781519e-07),\n",
       " (\"I'm like a fool, is this \", 8.156274213939073e-07),\n",
       " (\"I'm like Trump is at the \", 8.915109800065552e-07)]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for _ in range(100):\n",
    "    tweets.append(gen_tweet_given_start(\"I'm\", 5))\n",
    "curr = sorted(tweets, key = lambda x: x[1])[0:10]\n",
    "curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('many more VOTE and spirited crowd! ', 5.874501842243778e-07),\n",
       " ('many others in Louisiana. Big and ', 6.588136084538962e-07),\n",
       " ('many people in it. Lindsey got ', 6.815313190902374e-07),\n",
       " ('many will repeal and I am ', 6.987170045057804e-07),\n",
       " ('many of #CommonCore and Twitter poll- ', 7.08159126188291e-07),\n",
       " ('many people saying the record, most ', 7.657389993935348e-07),\n",
       " ('many voters by @CNN he was ', 8.514572081934511e-07),\n",
       " ('many years. He is that shows ', 1.075019135340609e-06),\n",
       " ('many believe @realDonaldTrump Wow! Thank you, ', 1.2365884706310241e-06),\n",
       " ('many of New National Poll, where ', 1.5304876975572648e-06)]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for _ in range(100):\n",
    "    tweets.append(gen_tweet_given_start(\"many\", 5))\n",
    "curr = sorted(tweets, key = lambda x: x[1])[20:30]\n",
    "curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('so happy & his fraudulent T.V. ', 1.1498852414529027e-06),\n",
       " ('so than a choker, always negative? ', 1.4694818019373646e-06),\n",
       " ('so good night. The New Hampshire. ', 1.51846452866861e-06),\n",
       " ('so out yesterday by Elton John ', 1.5526600171413663e-06),\n",
       " ('so easy to be president - ', 1.6079210909508772e-06),\n",
       " ('so much Jeb --- and I ', 1.6593014423892609e-06),\n",
       " ('so haltingly said that @oreillyfactor did ', 1.7353880327641257e-06),\n",
       " ('so impressive and then they like ', 1.8152422259226268e-06),\n",
       " ('so much more, he is 7,533,692-a ', 1.847603219818131e-06),\n",
       " ('so they say something much forward ', 2.0074919599947004e-06)]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for _ in range(100):\n",
    "    tweets.append(gen_tweet_given_start(\"so\", 5))\n",
    "curr = sorted(tweets, key = lambda x: x[1])[20:30]\n",
    "curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('no show that has never held ', 1.8590479164952853e-07),\n",
       " ('no money, no one will end ', 2.810033054418819e-07),\n",
       " ('no guts and payed for Cruz ', 2.980235080943185e-07),\n",
       " ('no buyers for lightweight from D.C. ', 3.14509914925068e-07),\n",
       " ('no chance in Cincinnati is why ', 3.8820659423249227e-07),\n",
       " ('no other politician and #VoteTrump tomorrow. ', 4.0597629585603754e-07),\n",
       " ('no clue & is a possible ', 4.5017283035302915e-07),\n",
       " ('no and said no buyer! Liabilities ', 4.79745159371342e-07),\n",
       " ('no chance in 4 or keeping ', 9.139030239223256e-07),\n",
       " ('no show first day to authorities ', 1.1083955420331298e-06)]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for _ in range(100):\n",
    "    tweets.append(gen_tweet_given_start(\"no\", 5))\n",
    "curr = sorted(tweets, key = lambda x: x[1])[10:20]\n",
    "curr"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
